{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42905aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import theano\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c48042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_observation(file=\"DMI-HIRHAM5_1980.nc\"):\n",
    "    \"\"\"\n",
    "    Read and return Obs\n",
    "    \"\"\"\n",
    "\n",
    "    with xr.open_dataset(file) as Obs:\n",
    "\n",
    "        stacked = Obs.stack(z=(\"rlat\", \"rlon\"))\n",
    "        ncl_stacked = Obs.stack(z=(\"ncl4\", \"ncl5\"))\n",
    "\n",
    "        temp = stacked.tas.dropna(dim=\"z\").values\n",
    "        rainfall = stacked.rainfall.dropna(dim=\"z\").values / 1000\n",
    "        snowfall = stacked.snfall.dropna(dim=\"z\").values / 1000\n",
    "        smb = stacked.gld.dropna(dim=\"z\").values / 1000\n",
    "        refreeze = ncl_stacked.rfrz.dropna(dim=\"z\").values / 1000\n",
    "        melt = stacked.snmel.dropna(dim=\"z\").values / 1000\n",
    "        precip = rainfall + snowfall\n",
    "\n",
    "    return (\n",
    "        temp,\n",
    "        precip,\n",
    "        smb.sum(axis=0),\n",
    "        refreeze.sum(axis=0),\n",
    "        snowfall.sum(axis=0),\n",
    "        refreeze.sum(axis=0),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2783bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_obs, P_obs, B_obs, R_obs, A_obs, M_obs = read_observation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694cff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.variational.ADVI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d8366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTPDDModel(object):\n",
    "    \"\"\"\n",
    "\n",
    "    # Copyright (c) 2013--2018, Julien Seguinot <seguinot@vaw.baug.ethz.ch>\n",
    "    # GNU General Public License v3.0+ (https://www.gnu.org/licenses/gpl-3.0.txt)\n",
    "\n",
    "    A positive degree day model for glacier surface mass balance\n",
    "\n",
    "    Return a callable Positive Degree Day (PDD) model instance.\n",
    "\n",
    "    Model parameters are held as public attributes, and can be set using\n",
    "    corresponding keyword arguments at initialization time:\n",
    "\n",
    "    *pdd_factor_snow* : float\n",
    "        Positive degree-day factor for snow.\n",
    "    *pdd_factor_ice* : float\n",
    "        Positive degree-day factor for ice.\n",
    "    *refreeze_snow* : float\n",
    "        Refreezing fraction of melted snow.\n",
    "    *refreeze_ice* : float\n",
    "        Refreezing fraction of melted ice.\n",
    "    *temp_snow* : float\n",
    "        Temperature at which all precipitation falls as snow.\n",
    "    *temp_rain* : float\n",
    "        Temperature at which all precipitation falls as rain.\n",
    "    *interpolate_rule* : [ 'linear' | 'nearest' | 'zero' |\n",
    "                           'slinear' | 'quadratic' | 'cubic' ]\n",
    "        Interpolation rule passed to `scipy.interpolate.interp1d`.\n",
    "    *interpolate_n*: int\n",
    "        Number of points used in interpolations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        pdd_factor_snow=0.003,\n",
    "        pdd_factor_ice=0.008,\n",
    "        refreeze_snow=0.0,\n",
    "        refreeze_ice=0.0,\n",
    "        temp_snow=0.0,\n",
    "        temp_rain=2.0,\n",
    "        interpolate_rule=\"linear\",\n",
    "        interpolate_n=52,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # set pdd model parameters\n",
    "        self.pdd_factor_snow = pdd_factor_snow\n",
    "        self.pdd_factor_ice = pdd_factor_ice\n",
    "        self.refreeze_snow = refreeze_snow\n",
    "        self.refreeze_ice = refreeze_ice\n",
    "        self.temp_snow = temp_snow\n",
    "        self.temp_rain = temp_rain\n",
    "        self.interpolate_rule = interpolate_rule\n",
    "        self.interpolate_n = interpolate_n\n",
    "\n",
    "    def __call__(self, temp, prec, stdv=0.0):\n",
    "        \"\"\"Run the positive degree day model.\n",
    "\n",
    "        Use temperature, precipitation, and standard deviation of temperature\n",
    "        to compute the number of positive degree days, accumulation and melt\n",
    "        surface mass fluxes, and the resulting surface mass balance.\n",
    "\n",
    "        *temp*: array_like\n",
    "            Input near-surface air temperature in degrees Celcius.\n",
    "        *prec*: array_like\n",
    "            Input precipitation rate in meter per year.\n",
    "        *stdv*: array_like (default 0.0)\n",
    "            Input standard deviation of near-surface air temperature in Kelvin.\n",
    "\n",
    "        By default, inputs are N-dimensional arrays whose first dimension is\n",
    "        interpreted as time and as periodic. Arrays of dimensions\n",
    "        N-1 are interpreted as constant in time and expanded to N dimensions.\n",
    "        Arrays of dimension 0 and numbers are interpreted as constant in time\n",
    "        and space and will be expanded too. The largest input array determines\n",
    "        the number of dimensions N.\n",
    "\n",
    "        Return the number of positive degree days ('pdd'), surface mass balance\n",
    "        ('smb'), and many other output variables in a dictionary.\n",
    "        \"\"\"\n",
    "\n",
    "        # ensure numpy arrays\n",
    "        temp = np.asarray(temp)\n",
    "        prec = np.asarray(prec)\n",
    "        stdv = np.asarray(stdv)\n",
    "\n",
    "        # expand arrays to the largest shape\n",
    "        maxshape = max(temp.shape, prec.shape, stdv.shape)\n",
    "        temp = self._expand(temp, maxshape)\n",
    "        prec = self._expand(prec, maxshape)\n",
    "        stdv = self._expand(stdv, maxshape)\n",
    "\n",
    "        # interpolate time-series\n",
    "        temp = self._interpolate(temp)\n",
    "        prec = self._interpolate(prec)\n",
    "        stdv = self._interpolate(stdv)\n",
    "\n",
    "        # compute accumulation and pdd\n",
    "        accu_rate = self.accu_rate(temp, prec)\n",
    "        inst_pdd = self.inst_pdd(temp, stdv)\n",
    "\n",
    "        # initialize snow depth, melt and refreeze rates\n",
    "        snow_depth = theano.shared(np.zeros_like(temp))\n",
    "        snow_melt_rate = theano.shared(np.zeros_like(temp))\n",
    "        ice_melt_rate = theano.shared(np.zeros_like(temp))\n",
    "        snow_refreeze_rate = theano.shared(np.zeros_like(temp))\n",
    "        ice_refreeze_rate = theano.shared(np.zeros_like(temp))\n",
    "\n",
    "        # compute snow depth and melt rates\n",
    "\n",
    "        for i in range(len(temp)):\n",
    "            if i > 0:\n",
    "                snow_depth = tt.set_subtensor(snow_depth[i], snow_depth[i - 1])\n",
    "            snow_depth = tt.inc_subtensor(snow_depth[i], accu_rate[i])\n",
    "            smr, imr = self.melt_rates(snow_depth[i], inst_pdd[i])\n",
    "            snow_melt_rate = tt.set_subtensor(snow_melt_rate[i], smr[i])\n",
    "            ice_melt_rate = tt.set_subtensor(ice_melt_rate[i], imr[i])\n",
    "            snow_depth = tt.inc_subtensor(snow_depth[i], - snow_melt_rate[i])\n",
    "            \n",
    "        melt_rate = snow_melt_rate + ice_melt_rate\n",
    "        snow_refreeze_rate = self.refreeze_snow * snow_melt_rate\n",
    "        ice_refreeze_rate = self.refreeze_ice * ice_melt_rate\n",
    "        refreeze_rate = snow_refreeze_rate + ice_refreeze_rate\n",
    "        runoff_rate = melt_rate - refreeze_rate\n",
    "        inst_smb = accu_rate - runoff_rate\n",
    "\n",
    "        # output\n",
    "        return {\n",
    "            \"temp\": temp,\n",
    "            \"prec\": prec,\n",
    "            \"stdv\": stdv,\n",
    "            \"inst_pdd\": inst_pdd,\n",
    "            \"accu_rate\": accu_rate,\n",
    "            \"snow_melt_rate\": snow_melt_rate,\n",
    "            \"ice_melt_rate\": ice_melt_rate,\n",
    "            \"melt_rate\": melt_rate,\n",
    "            \"snow_refreeze_rate\": snow_refreeze_rate,\n",
    "            \"ice_refreeze_rate\": ice_refreeze_rate,\n",
    "            \"refreeze_rate\": refreeze_rate,\n",
    "            \"runoff_rate\": runoff_rate,\n",
    "            \"inst_smb\": inst_smb,\n",
    "            \"snow_depth\": snow_depth,\n",
    "            \"pdd\": self._integrate(inst_pdd),\n",
    "            \"accu\": self._integrate(accu_rate),\n",
    "            \"snow_melt\": self._integrate(snow_melt_rate),\n",
    "            \"ice_melt\": self._integrate(ice_melt_rate),\n",
    "            \"melt\": self._integrate(melt_rate),\n",
    "            \"runoff\": self._integrate(runoff_rate),\n",
    "            \"refreeze\": self._integrate(refreeze_rate),\n",
    "            \"smb\": self._integrate(inst_smb),\n",
    "        }\n",
    "\n",
    "    def _expand(self, array, shape):\n",
    "        \"\"\"Expand an array to the given shape\"\"\"\n",
    "        if array.shape == shape:\n",
    "            res = array\n",
    "        elif array.shape == (1, shape[1], shape[2]):\n",
    "            res = np.asarray([array[0]] * shape[0])\n",
    "        elif array.shape == shape[1:]:\n",
    "            res = np.asarray([array] * shape[0])\n",
    "        elif array.shape == ():\n",
    "            res = array * np.ones(shape)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"could not expand array of shape %s to %s\" % (array.shape, shape)\n",
    "            )\n",
    "        return res\n",
    "\n",
    "    def _integrate(self, array):\n",
    "        \"\"\"Integrate an array over one year\"\"\"\n",
    "        return tt.sum(array, axis=0) / (self.interpolate_n - 1)\n",
    "\n",
    "    def _interpolate(self, array):\n",
    "        \"\"\"Interpolate an array through one year.\"\"\"\n",
    "        from scipy.interpolate import interp1d\n",
    "\n",
    "        rule = self.interpolate_rule\n",
    "        npts = self.interpolate_n\n",
    "        oldx = (np.arange(len(array) + 2) - 0.5) / len(array)\n",
    "        oldy = np.vstack(([array[-1]], array, [array[0]]))\n",
    "        newx = (np.arange(npts) + 0.5) / npts  # use 0.0 for PISM-like behaviour\n",
    "        newy = interp1d(oldx, oldy, kind=rule, axis=0)(newx)\n",
    "        return newy\n",
    "\n",
    "    def inst_pdd(self, temp, stdv):\n",
    "        \"\"\"Compute instantaneous positive degree days from temperature.\n",
    "\n",
    "        Use near-surface air temperature and standard deviation to compute\n",
    "        instantaneous positive degree days (effective temperature for melt,\n",
    "        unit degrees C) using an integral formulation (Calov and Greve, 2005).\n",
    "\n",
    "        *temp*: array_like\n",
    "            Near-surface air temperature in degrees Celcius.\n",
    "        *stdv*: array_like\n",
    "            Standard deviation of near-surface air temperature in Kelvin.\n",
    "        \"\"\"\n",
    "\n",
    "        # compute positive part of temperature everywhere\n",
    "        positivepart = tt.gt(temp, 0) * temp\n",
    "\n",
    "        # compute Calov and Greve (2005) integrand, ignoring division by zero\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            normtemp = temp / (np.sqrt(2) * stdv)\n",
    "        calovgreve = stdv / np.sqrt(2 * np.pi) * tt.exp(\n",
    "            -(normtemp**2)\n",
    "        ) + temp / 2 * tt.erfc(-normtemp)\n",
    "\n",
    "        # use positive part where sigma is zero and Calov and Greve elsewhere\n",
    "        teff = tt.where(stdv == 0.0, positivepart, calovgreve)\n",
    "\n",
    "        # convert to degree-days\n",
    "        return teff * 365.242198781\n",
    "\n",
    "    def accu_rate(self, temp, prec):\n",
    "        \"\"\"Compute accumulation rate from temperature and precipitation.\n",
    "\n",
    "        The fraction of precipitation that falls as snow decreases linearly\n",
    "        from one to zero between temperature thresholds defined by the\n",
    "        `temp_snow` and `temp_rain` attributes.\n",
    "\n",
    "        *temp*: array_like\n",
    "            Near-surface air temperature in degrees Celcius.\n",
    "        *prec*: array_like\n",
    "            Precipitation rate in meter per year.\n",
    "        \"\"\"\n",
    "\n",
    "        # compute snow fraction as a function of temperature\n",
    "        reduced_temp = (self.temp_rain - temp) / (self.temp_rain - self.temp_snow)\n",
    "        snowfrac = tt.clip(reduced_temp, 0, 1)\n",
    "\n",
    "        # return accumulation rate\n",
    "        return snowfrac * prec\n",
    "\n",
    "    def melt_rates(self, snow, pdd):\n",
    "        \"\"\"Compute melt rates from snow precipitation and pdd sum.\n",
    "\n",
    "        Snow melt is computed from the number of positive degree days (*pdd*)\n",
    "        and the `pdd_factor_snow` model attribute. If all snow is melted and\n",
    "        some energy (PDD) remains, ice melt is computed using `pdd_factor_ice`.\n",
    "\n",
    "        *snow*: array_like\n",
    "            Snow precipitation rate.\n",
    "        *pdd*: array_like\n",
    "            Number of positive degree days.\n",
    "        \"\"\"\n",
    "\n",
    "        # parse model parameters for readability\n",
    "        ddf_snow = self.pdd_factor_snow\n",
    "        ddf_ice = self.pdd_factor_ice\n",
    "\n",
    "        # compute a potential snow melt\n",
    "        pot_snow_melt = ddf_snow * pdd\n",
    "\n",
    "        # effective snow melt can't exceed amount of snow\n",
    "        snow_melt = tt.minimum(snow, pot_snow_melt)\n",
    "\n",
    "        # ice melt is proportional to excess snow melt\n",
    "        ice_melt = (pot_snow_melt - snow_melt) * ddf_ice / ddf_snow\n",
    "\n",
    "        # return melt rates\n",
    "        return (snow_melt, ice_melt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8741f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdd_model = TTPDDModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeee2b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pdd_model(T_obs, P_obs, np.ones_like(T_obs) + 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b76b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = result[\"accu_rate\"]\n",
    "M = result[\"melt_rate\"]\n",
    "R = result[\"refreeze_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4cff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.eval().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906061b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncpdd_model = PDDModel()\n",
    "ncresult = ncpdd_model(T_obs, P_obs, np.ones_like(T_obs) + 4)\n",
    "Anc = ncresult[\"accu_rate\"]\n",
    "Mnc = ncresult[\"melt_rate\"]\n",
    "Rnc = ncresult[\"refreeze_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795d540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629cb483",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e00977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDDModel(object):\n",
    "    \"\"\"\n",
    "\n",
    "    # Copyright (c) 2013--2018, Julien Seguinot <seguinot@vaw.baug.ethz.ch>\n",
    "    # GNU General Public License v3.0+ (https://www.gnu.org/licenses/gpl-3.0.txt)\n",
    "\n",
    "    A positive degree day model for glacier surface mass balance\n",
    "\n",
    "    Return a callable Positive Degree Day (PDD) model instance.\n",
    "\n",
    "    Model parameters are held as public attributes, and can be set using\n",
    "    corresponding keyword arguments at initialization time:\n",
    "\n",
    "    *pdd_factor_snow* : float\n",
    "        Positive degree-day factor for snow.\n",
    "    *pdd_factor_ice* : float\n",
    "        Positive degree-day factor for ice.\n",
    "    *refreeze_snow* : float\n",
    "        Refreezing fraction of melted snow.\n",
    "    *refreeze_ice* : float\n",
    "        Refreezing fraction of melted ice.\n",
    "    *temp_snow* : float\n",
    "        Temperature at which all precipitation falls as snow.\n",
    "    *temp_rain* : float\n",
    "        Temperature at which all precipitation falls as rain.\n",
    "    *interpolate_rule* : [ 'linear' | 'nearest' | 'zero' |\n",
    "                           'slinear' | 'quadratic' | 'cubic' ]\n",
    "        Interpolation rule passed to `scipy.interpolate.interp1d`.\n",
    "    *interpolate_n*: int\n",
    "        Number of points used in interpolations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        pdd_factor_snow=0.003,\n",
    "        pdd_factor_ice=0.008,\n",
    "        refreeze_snow=0.0,\n",
    "        refreeze_ice=0.0,\n",
    "        temp_snow=0.0,\n",
    "        temp_rain=2.0,\n",
    "        interpolate_rule=\"linear\",\n",
    "        interpolate_n=52,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # set pdd model parameters\n",
    "        self.pdd_factor_snow = pdd_factor_snow\n",
    "        self.pdd_factor_ice = pdd_factor_ice\n",
    "        self.refreeze_snow = refreeze_snow\n",
    "        self.refreeze_ice = refreeze_ice\n",
    "        self.temp_snow = temp_snow\n",
    "        self.temp_rain = temp_rain\n",
    "        self.interpolate_rule = interpolate_rule\n",
    "        self.interpolate_n = interpolate_n\n",
    "\n",
    "    def __call__(self, temp, prec, stdv=0.0):\n",
    "        \"\"\"Run the positive degree day model.\n",
    "\n",
    "        Use temperature, precipitation, and standard deviation of temperature\n",
    "        to compute the number of positive degree days, accumulation and melt\n",
    "        surface mass fluxes, and the resulting surface mass balance.\n",
    "\n",
    "        *temp*: array_like\n",
    "            Input near-surface air temperature in degrees Celcius.\n",
    "        *prec*: array_like\n",
    "            Input precipitation rate in meter per year.\n",
    "        *stdv*: array_like (default 0.0)\n",
    "            Input standard deviation of near-surface air temperature in Kelvin.\n",
    "\n",
    "        By default, inputs are N-dimensional arrays whose first dimension is\n",
    "        interpreted as time and as periodic. Arrays of dimensions\n",
    "        N-1 are interpreted as constant in time and expanded to N dimensions.\n",
    "        Arrays of dimension 0 and numbers are interpreted as constant in time\n",
    "        and space and will be expanded too. The largest input array determines\n",
    "        the number of dimensions N.\n",
    "\n",
    "        Return the number of positive degree days ('pdd'), surface mass balance\n",
    "        ('smb'), and many other output variables in a dictionary.\n",
    "        \"\"\"\n",
    "\n",
    "        # ensure numpy arrays\n",
    "        temp = np.asarray(temp)\n",
    "        prec = np.asarray(prec)\n",
    "        stdv = np.asarray(stdv)\n",
    "\n",
    "        # expand arrays to the largest shape\n",
    "        maxshape = max(temp.shape, prec.shape, stdv.shape)\n",
    "        temp = self._expand(temp, maxshape)\n",
    "        prec = self._expand(prec, maxshape)\n",
    "        stdv = self._expand(stdv, maxshape)\n",
    "\n",
    "        # interpolate time-series\n",
    "        temp = self._interpolate(temp)\n",
    "        prec = self._interpolate(prec)\n",
    "        stdv = self._interpolate(stdv)\n",
    "\n",
    "        # compute accumulation and pdd\n",
    "        accu_rate = self.accu_rate(temp, prec)\n",
    "        inst_pdd = self.inst_pdd(temp, stdv)\n",
    "\n",
    "        # initialize snow depth, melt and refreeze rates\n",
    "        snow_depth = np.zeros_like(temp)\n",
    "        snow_melt_rate = np.zeros_like(temp)\n",
    "        ice_melt_rate = np.zeros_like(temp)\n",
    "        snow_refreeze_rate = np.zeros_like(temp)\n",
    "        ice_refreeze_rate = np.zeros_like(temp)\n",
    "\n",
    "        # compute snow depth and melt rates\n",
    "        for i in range(len(temp)):\n",
    "            if i > 0:\n",
    "                snow_depth[i] = snow_depth[i - 1]\n",
    "            snow_depth[i] += accu_rate[i]\n",
    "            snow_melt_rate[i], ice_melt_rate[i] = self.melt_rates(\n",
    "                snow_depth[i], inst_pdd[i]\n",
    "            )\n",
    "            snow_depth[i] -= snow_melt_rate[i]\n",
    "\n",
    "        melt_rate = snow_melt_rate + ice_melt_rate\n",
    "        snow_refreeze_rate = self.refreeze_snow * snow_melt_rate\n",
    "        ice_refreeze_rate = self.refreeze_ice * ice_melt_rate\n",
    "        refreeze_rate = snow_refreeze_rate + ice_refreeze_rate\n",
    "        runoff_rate = melt_rate - refreeze_rate\n",
    "        inst_smb = accu_rate - runoff_rate\n",
    "\n",
    "        # output\n",
    "        return {\n",
    "            \"temp\": temp,\n",
    "            \"prec\": prec,\n",
    "            \"stdv\": stdv,\n",
    "            \"inst_pdd\": inst_pdd,\n",
    "            \"accu_rate\": accu_rate,\n",
    "            \"snow_melt_rate\": snow_melt_rate,\n",
    "            \"ice_melt_rate\": ice_melt_rate,\n",
    "            \"melt_rate\": melt_rate,\n",
    "            \"snow_refreeze_rate\": snow_refreeze_rate,\n",
    "            \"ice_refreeze_rate\": ice_refreeze_rate,\n",
    "            \"refreeze_rate\": refreeze_rate,\n",
    "            \"runoff_rate\": runoff_rate,\n",
    "            \"inst_smb\": inst_smb,\n",
    "            \"snow_depth\": snow_depth,\n",
    "            \"pdd\": self._integrate(inst_pdd),\n",
    "            \"accu\": self._integrate(accu_rate),\n",
    "            \"snow_melt\": self._integrate(snow_melt_rate),\n",
    "            \"ice_melt\": self._integrate(ice_melt_rate),\n",
    "            \"melt\": self._integrate(melt_rate),\n",
    "            \"runoff\": self._integrate(runoff_rate),\n",
    "            \"refreeze\": self._integrate(refreeze_rate),\n",
    "            \"smb\": self._integrate(inst_smb),\n",
    "        }\n",
    "\n",
    "    def _expand(self, array, shape):\n",
    "        \"\"\"Expand an array to the given shape\"\"\"\n",
    "        if array.shape == shape:\n",
    "            res = array\n",
    "        elif array.shape == (1, shape[1], shape[2]):\n",
    "            res = np.asarray([array[0]] * shape[0])\n",
    "        elif array.shape == shape[1:]:\n",
    "            res = np.asarray([array] * shape[0])\n",
    "        elif array.shape == ():\n",
    "            res = array * np.ones(shape)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"could not expand array of shape %s to %s\" % (array.shape, shape)\n",
    "            )\n",
    "        return res\n",
    "\n",
    "    def _integrate(self, array):\n",
    "        \"\"\"Integrate an array over one year\"\"\"\n",
    "        return np.sum(array, axis=0) / (self.interpolate_n - 1)\n",
    "\n",
    "    def _interpolate(self, array):\n",
    "        \"\"\"Interpolate an array through one year.\"\"\"\n",
    "        from scipy.interpolate import interp1d\n",
    "\n",
    "        rule = self.interpolate_rule\n",
    "        npts = self.interpolate_n\n",
    "        oldx = (np.arange(len(array) + 2) - 0.5) / len(array)\n",
    "        oldy = np.vstack(([array[-1]], array, [array[0]]))\n",
    "        newx = (np.arange(npts) + 0.5) / npts  # use 0.0 for PISM-like behaviour\n",
    "        newy = interp1d(oldx, oldy, kind=rule, axis=0)(newx)\n",
    "        return newy\n",
    "\n",
    "    def inst_pdd(self, temp, stdv):\n",
    "        \"\"\"Compute instantaneous positive degree days from temperature.\n",
    "\n",
    "        Use near-surface air temperature and standard deviation to compute\n",
    "        instantaneous positive degree days (effective temperature for melt,\n",
    "        unit degrees C) using an integral formulation (Calov and Greve, 2005).\n",
    "\n",
    "        *temp*: array_like\n",
    "            Near-surface air temperature in degrees Celcius.\n",
    "        *stdv*: array_like\n",
    "            Standard deviation of near-surface air temperature in Kelvin.\n",
    "        \"\"\"\n",
    "        import scipy.special as sp\n",
    "\n",
    "        # compute positive part of temperature everywhere\n",
    "        positivepart = np.greater(temp, 0) * temp\n",
    "\n",
    "        # compute Calov and Greve (2005) integrand, ignoring division by zero\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            normtemp = temp / (np.sqrt(2) * stdv)\n",
    "        calovgreve = stdv / np.sqrt(2 * np.pi) * np.exp(\n",
    "            -(normtemp**2)\n",
    "        ) + temp / 2 * sp.erfc(-normtemp)\n",
    "\n",
    "        # use positive part where sigma is zero and Calov and Greve elsewhere\n",
    "        teff = np.where(stdv == 0.0, positivepart, calovgreve)\n",
    "\n",
    "        # convert to degree-days\n",
    "        return teff * 365.242198781\n",
    "\n",
    "    def accu_rate(self, temp, prec):\n",
    "        \"\"\"Compute accumulation rate from temperature and precipitation.\n",
    "\n",
    "        The fraction of precipitation that falls as snow decreases linearly\n",
    "        from one to zero between temperature thresholds defined by the\n",
    "        `temp_snow` and `temp_rain` attributes.\n",
    "\n",
    "        *temp*: array_like\n",
    "            Near-surface air temperature in degrees Celcius.\n",
    "        *prec*: array_like\n",
    "            Precipitation rate in meter per year.\n",
    "        \"\"\"\n",
    "\n",
    "        # compute snow fraction as a function of temperature\n",
    "        reduced_temp = (self.temp_rain - temp) / (self.temp_rain - self.temp_snow)\n",
    "        snowfrac = np.clip(reduced_temp, 0, 1)\n",
    "\n",
    "        # return accumulation rate\n",
    "        return snowfrac * prec\n",
    "\n",
    "    def melt_rates(self, snow, pdd):\n",
    "        \"\"\"Compute melt rates from snow precipitation and pdd sum.\n",
    "\n",
    "        Snow melt is computed from the number of positive degree days (*pdd*)\n",
    "        and the `pdd_factor_snow` model attribute. If all snow is melted and\n",
    "        some energy (PDD) remains, ice melt is computed using `pdd_factor_ice`.\n",
    "\n",
    "        *snow*: array_like\n",
    "            Snow precipitation rate.\n",
    "        *pdd*: array_like\n",
    "            Number of positive degree days.\n",
    "        \"\"\"\n",
    "\n",
    "        # parse model parameters for readability\n",
    "        ddf_snow = self.pdd_factor_snow\n",
    "        ddf_ice = self.pdd_factor_ice\n",
    "\n",
    "        # compute a potential snow melt\n",
    "        pot_snow_melt = ddf_snow * pdd\n",
    "\n",
    "        # effective snow melt can't exceed amount of snow\n",
    "        snow_melt = np.minimum(snow, pot_snow_melt)\n",
    "\n",
    "        # ice melt is proportional to excess snow melt\n",
    "        ice_melt = (pot_snow_melt - snow_melt) * ddf_ice / ddf_snow\n",
    "\n",
    "        # return melt rates\n",
    "        return (snow_melt, ice_melt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8954bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run MCMC_inversion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a8b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "theano.shared?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7c9b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.as_tensor_variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69cc6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from theano.tensor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e077b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.gt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34b462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de6df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.greater?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca5675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.erf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d768e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8d6706",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.erf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f93fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.erfc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff1a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones((300, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb3dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = theano.shared(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27955cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71cc34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simultaneous_fit_LA(\n",
    "    T_obs, P_obs, R_obs, A_obs, M_obs, B_obs, draws=4000, tune=2000, cores=1\n",
    "):\n",
    "    \"\"\"Simultaneous fitting the linear accumulation model\"\"\"\n",
    "\n",
    "    const = dict()\n",
    "\n",
    "    # initialize the PDD melt model class\n",
    "    PDD_forward = PDD_MCMC(**const)\n",
    "\n",
    "    # Define Priors\n",
    "    with pm.Model() as model:\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        # ----> Mass balance Model (physical priors)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        f_snow_prior = pm.TruncatedNormal(\"f_snow\", mu=4.1, sigma=1.5, lower=0.0)\n",
    "        f_ice_prior = pm.TruncatedNormal(\"f_ice\", mu=8.0, sigma=2.0, lower=0.0)\n",
    "        f_refreeze_prior = pm.TruncatedNormal(\n",
    "            \"f_refreeze\", mu=0.5, sigma=0.2, lower=0.0, upper=1\n",
    "        )\n",
    "\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        # ----> Hyperparameters (likelihood related priors)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        R_sigma = pm.HalfCauchy(\"R_sigma\", 0.5)\n",
    "        A_sigma = pm.HalfCauchy(\"A_sigma\", 2)\n",
    "        M_sigma = pm.HalfCauchy(\"M_sigma\", 5)\n",
    "\n",
    "    # Define Forward model (wrapped through theano)\n",
    "    with model:\n",
    "        R, A, M = PDD_forward.forward(\n",
    "            T_obs,\n",
    "            P_obs,\n",
    "            np.zeros_like(T_obs),\n",
    "            f_snow_prior,\n",
    "            f_ice_prior,\n",
    "            f_refreeze_prior,\n",
    "        )\n",
    "        # net balance [m i.e. / yr ]\n",
    "        B = A + R - M\n",
    "\n",
    "    # Define likelihood (function?)\n",
    "    with model:\n",
    "        # Individual likelihood functions for each component\n",
    "        R_est = pm.Normal(\"R_est\", mu=R, sigma=R_sigma, observed=R_obs)\n",
    "        A_est = pm.Normal(\"A_est\", mu=A, sigma=A_sigma, observed=A_obs)\n",
    "        M_est = pm.Normal(\"M_est\", mu=M, sigma=M_sigma, observed=M_obs)\n",
    "\n",
    "        potential = pm.Potential(\"obs\", R_est.sum() * A_est.sum() * M_est.sum())\n",
    "\n",
    "    # run inference: Sample\n",
    "    with model:\n",
    "        trace = pm.sample(\n",
    "            init=\"advi\",\n",
    "            draws=draws,\n",
    "            tune=tune,\n",
    "            cores=cores,\n",
    "            target_accept=0.9,\n",
    "            return_inferencedata=True,\n",
    "        )\n",
    "\n",
    "    # do posterior predictive inference\n",
    "    with model:\n",
    "        ppc = pm.sample_posterior_predictive(\n",
    "            trace, var_names=[\"R_est\", \"A_est\", \"M_est\"], keep_size=True\n",
    "        )\n",
    "        pp_R = ppc[\"R_est\"]\n",
    "        pp_A = ppc[\"A_est\"]\n",
    "        pp_M = ppc[\"M_est\"]\n",
    "        pp_B = pp_A + pp_R - pp_M\n",
    "\n",
    "    return model, trace, pp_R, pp_A, pp_M, pp_B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078bddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "run MCMC_inversion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c64c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_LA(\"simultaneous\", cores=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0223ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    means = approx.bij.rmap(approx.mean.eval())\n",
    "    sds = approx.bij.rmap(approx.std.eval())\n",
    "    import seaborn as sns\n",
    "\n",
    "    from scipy import stats\n",
    "\n",
    "    varnames = means.keys()\n",
    "    fig, axs = plt.subplots(nrows=len(varnames), figsize=(12, 18))\n",
    "    for var, ax in zip(varnames, axs):\n",
    "        mu_arr = means[var]\n",
    "        sigma_arr = sds[var]\n",
    "        ax.set_title(var)\n",
    "        for i, (mu, sigma) in enumerate(zip(mu_arr.flatten(), sigma_arr.flatten())):\n",
    "            sd3 = (-4 * sigma + mu, 4 * sigma + mu)\n",
    "            x = np.linspace(sd3[0], sd3[1], 300)\n",
    "            y = stats.norm(mu, sigma).pdf(x)\n",
    "            ax.plot(x, y)\n",
    "    fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4274ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with model:\n",
    "    trace = pm.sample(\n",
    "        init=\"advi\",\n",
    "        draws=draws,\n",
    "        tune=tune,\n",
    "        cores=cores,\n",
    "        target_accept=0.9,\n",
    "        return_inferencedata=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c4973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "        model, trace, pp_R, pp_A, pp_M, pp_B = simultaneous_fit_LA(\n",
    "            T_obs, P_obs, R_obs, A_obs, M_obs, B_obs, draws, tune, cores\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abc79e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simultaneous_fit_LA(\n",
    "    T_obs, P_obs, R_obs, A_obs, M_obs, B_obs, draws=500, tune=500, cores=4\n",
    "):\n",
    "    \"\"\"Simultaneous fitting the linear accumulation model\"\"\"\n",
    "\n",
    "    const = dict()\n",
    "\n",
    "    # initialize the PDD melt model class\n",
    "    PDD_forward = PDD_MCMC(**const)\n",
    "\n",
    "    # Define Priors\n",
    "    with pm.Model() as model:\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        # ----> Mass balance Model (physical priors)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        f_snow_prior = pm.TruncatedNormal(\"f_snow\", mu=4.1, sigma=1.5, lower=0.0)\n",
    "        f_ice_prior = pm.TruncatedNormal(\"f_ice\", mu=8.0, sigma=2.0, lower=0.0)\n",
    "        f_refreeze_prior = pm.TruncatedNormal(\n",
    "            \"f_refreeze\", mu=0.5, sigma=0.2, lower=0.0, upper=1\n",
    "        )\n",
    "\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        # ----> Hyperparameters (likelihood related priors)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        R_sigma = pm.HalfCauchy(\"R_sigma\", 0.5)\n",
    "        A_sigma = pm.HalfCauchy(\"A_sigma\", 2)\n",
    "        M_sigma = pm.HalfCauchy(\"M_sigma\", 5)\n",
    "\n",
    "    # Define Forward model (wrapped through theano)\n",
    "    with model:\n",
    "        R, A, M = PDD_forward.forward(\n",
    "            T_obs,\n",
    "            P_obs,\n",
    "            np.zeros_like(T_obs),\n",
    "            f_snow_prior,\n",
    "            f_ice_prior,\n",
    "            f_refreeze_prior,\n",
    "        )\n",
    "        # net balance [m i.e. / yr ]\n",
    "        B = A + R - M\n",
    "\n",
    "    # Define likelihood (function?)\n",
    "    with model:\n",
    "        # Individual likelihood functions for each component\n",
    "        R_est = pm.Normal(\"R_est\", mu=R, sigma=R_sigma, observed=R_obs)\n",
    "        A_est = pm.Normal(\"A_est\", mu=A, sigma=A_sigma, observed=A_obs)\n",
    "        M_est = pm.Normal(\"M_est\", mu=M, sigma=M_sigma, observed=M_obs)\n",
    "\n",
    "        potential = pm.Potential(\"obs\", R_est.sum() * A_est.sum() * M_est.sum())\n",
    "\n",
    "    with model:\n",
    "        approx = pm.fit(\n",
    "            draws, callbacks=[pm.callbacks.CheckParametersConvergence(tolerance=1e-4)]\n",
    "        )\n",
    "\n",
    "    # run inference: Sample\n",
    "#     with model:\n",
    "#         trace = pm.sample(\n",
    "#             init=\"advi\",\n",
    "#             draws=draws,\n",
    "#             tune=tune,\n",
    "#             cores=cores,\n",
    "#             target_accept=0.9,\n",
    "#             return_inferencedata=True,\n",
    "#         )\n",
    "\n",
    "    # do posterior predictive inference\n",
    "    with model:\n",
    "        ppc = pm.sample_posterior_predictive(\n",
    "            trace, var_names=[\"R_est\", \"A_est\", \"M_est\"], keep_size=True\n",
    "        )\n",
    "        pp_R = ppc[\"R_est\"]\n",
    "        pp_A = ppc[\"A_est\"]\n",
    "        pp_M = ppc[\"M_est\"]\n",
    "        pp_B = pp_A + pp_R - pp_M\n",
    "\n",
    "    return model, approx, pp_R, pp_A, pp_M, pp_B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe95c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    const = dict()\n",
    "\n",
    "    # initialize the PDD melt model class\n",
    "    PDD_forward = PDD_MCMC(**const)\n",
    "\n",
    "    # Define Priors\n",
    "    with pm.Model() as model:\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        # ----> Mass balance Model (physical priors)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        f_snow_prior = pm.TruncatedNormal(\"f_snow\", mu=4.1, sigma=1.5, lower=0.0)\n",
    "        f_ice_prior = pm.TruncatedNormal(\"f_ice\", mu=8.0, sigma=2.0, lower=0.0)\n",
    "        f_refreeze_prior = pm.TruncatedNormal(\n",
    "            \"f_refreeze\", mu=0.5, sigma=0.2, lower=0.0, upper=1\n",
    "        )\n",
    "\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        # ----> Hyperparameters (likelihood related priors)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        R_sigma = pm.HalfCauchy(\"R_sigma\", 0.5)\n",
    "        A_sigma = pm.HalfCauchy(\"A_sigma\", 2)\n",
    "        M_sigma = pm.HalfCauchy(\"M_sigma\", 5)\n",
    "\n",
    "    # Define Forward model (wrapped through theano)\n",
    "    with model:\n",
    "        R, A, M = PDD_forward.forward(\n",
    "            T_obs,\n",
    "            P_obs,\n",
    "            np.zeros_like(T_obs),\n",
    "            f_snow_prior,\n",
    "            f_ice_prior,\n",
    "            f_refreeze_prior,\n",
    "        )\n",
    "        # net balance [m i.e. / yr ]\n",
    "        B = A + R - M\n",
    "\n",
    "    # Define likelihood (function?)\n",
    "    with model:\n",
    "        # Individual likelihood functions for each component\n",
    "        R_est = pm.Normal(\"R_est\", mu=R, sigma=R_sigma, observed=R_obs)\n",
    "        A_est = pm.Normal(\"A_est\", mu=A, sigma=A_sigma, observed=A_obs)\n",
    "        M_est = pm.Normal(\"M_est\", mu=M, sigma=M_sigma, observed=M_obs)\n",
    "\n",
    "        potential = pm.Potential(\"obs\", R_est.sum() * A_est.sum() * M_est.sum())\n",
    "\n",
    "    with model:\n",
    "        approx = pm.fit(\n",
    "            draws, callbacks=[pm.callbacks.CheckParametersConvergence(tolerance=1e-4)]\n",
    "        )\n",
    "\n",
    "    means = approx.bij.rmap(approx.mean.eval())\n",
    "    sds = approx.bij.rmap(approx.std.eval())\n",
    "    import seaborn as sns\n",
    "\n",
    "    from scipy import stats\n",
    "\n",
    "    varnames = means.keys()\n",
    "    fig, axs = plt.subplots(nrows=len(varnames), figsize=(12, 18))\n",
    "    for var, ax in zip(varnames, axs):\n",
    "        mu_arr = means[var]\n",
    "        sigma_arr = sds[var]\n",
    "        ax.set_title(var)\n",
    "        for i, (mu, sigma) in enumerate(zip(mu_arr.flatten(), sigma_arr.flatten())):\n",
    "            sd3 = (-4 * sigma + mu, 4 * sigma + mu)\n",
    "            x = np.linspace(sd3[0], sd3[1], 300)\n",
    "            y = stats.norm(mu, sigma).pdf(x)\n",
    "            ax.plot(x, y)\n",
    "    fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81695423",
   "metadata": {},
   "outputs": [],
   "source": [
    "    const = dict()\n",
    "\n",
    "    # initialize the PDD melt model class\n",
    "    PDD_forward = PDD_MCMC(**const)\n",
    "\n",
    "    # Define Priors\n",
    "    with pm.Model() as model:\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        # ----> Mass balance Model (physical priors)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        f_snow_prior = pm.TruncatedNormal(\"f_snow\", mu=4.1, sigma=1.5, lower=0.0)\n",
    "        f_ice_prior = pm.TruncatedNormal(\"f_ice\", mu=8.0, sigma=2.0, lower=0.0)\n",
    "        f_refreeze_prior = pm.TruncatedNormal(\n",
    "            \"f_refreeze\", mu=0.5, sigma=0.2, lower=0.0, upper=1\n",
    "        )\n",
    "\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        # ----> Hyperparameters (likelihood related priors)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        sigma = pm.HalfCauchy(\"R_sigma\", 1, shape=3)\n",
    "\n",
    "    # Define Forward model (wrapped through theano)\n",
    "    with model:\n",
    "        R, A, M = PDD_forward.forward(\n",
    "            T_obs,\n",
    "            P_obs,\n",
    "            np.zeros_like(T_obs),\n",
    "            f_snow_prior,\n",
    "            f_ice_prior,\n",
    "            f_refreeze_prior,\n",
    "        )\n",
    "        # net balance [m i.e. / yr ]\n",
    "        B = A + R - M\n",
    "\n",
    "    # Define likelihood (function?)\n",
    "    with model:\n",
    "        # Individual likelihood functions for each component\n",
    "        est = pm.Normal(\n",
    "            \"est\",\n",
    "            mu=np.array([R, A, M]),\n",
    "            sigma=sigma,\n",
    "            observed=theano.shared([R_obs, A_obs, M_obs]),\n",
    "        )\n",
    "\n",
    "    with model:\n",
    "        approx = pm.fit(\n",
    "            draws, callbacks=[pm.callbacks.CheckParametersConvergence(tolerance=1e-4)]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7520b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.Cauchy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564633e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import scipy.stats as st\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "    x = np.linspace(-5, 5, 500)\n",
    "    alphas = [0., 0., 0., -2.]\n",
    "    betas = [.5, 1., 2., 1.]\n",
    "    for a, b in zip(alphas, betas):\n",
    "        pdf = st.cauchy.pdf(x, loc=a, scale=b)\n",
    "        plt.plot(x, pdf, label=r'$\\alpha$ = {}, $\\beta$ = {}'.format(a, b))\n",
    "    plt.xlabel('x', fontsize=12)\n",
    "    plt.ylabel('f(x)', fontsize=12)\n",
    "    plt.legend(loc=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d28451",
   "metadata": {},
   "outputs": [],
   "source": [
    "run MCMC_inversion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563d28d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
